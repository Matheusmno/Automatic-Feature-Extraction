{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyedflib\n",
    "import plotly.express as px\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import EDF_wrapper\n",
    "import filters\n",
    "import re\n",
    "from SwallowDetection.SwallowAnntations import get_swallow_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = Path(\"data/edf/\")\n",
    "files = EDF_wrapper.read_files_from_dir(directory, load_files=True)\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_swallow_annotations(files: list, output_path:str=\"data/annotations/\"):\n",
    "    \n",
    "    # Extract annotations from signal\n",
    "    ann = []    \n",
    "    for edf_file in np.asarray([file['filepath'] for file in files]):\n",
    "        try:\n",
    "            ann.append(get_swallow_annotations(edf_file))\n",
    "        except:\n",
    "            print(f\"File {edf_file} failed to get swallow annotations.\")\n",
    "    \n",
    "    for file, (times, annotations) in zip(files, ann):\n",
    "        # Add extracted annotations to file's annotation list\n",
    "        for time, annotation in zip(times, annotations):\n",
    "            file['header']['annotations'].append([time, -1, annotation])\n",
    "            \n",
    "        file['header']['annotations'].sort(key=lambda x: x[0])\n",
    "        # Save edited edf file\n",
    "        EDF_wrapper.save_edf_file(file, output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_swallow_annotations(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_file = pyedflib.highlevel.read_edf_header(f\"data/annotations/{Path(files[3]['filepath']).name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2.8425, -1, 'Schlucken normal'],\n",
       " [5.925, -1, 'C_category2_start'],\n",
       " [6.64, -1, 's_swallow_start'],\n",
       " [6.687, -1, 'P_elevation_start'],\n",
       " [6.687, -1, 'P_swallow_start'],\n",
       " [7.304, -1, 'P_elevation_stop'],\n",
       " [7.304, -1, 'P_lowering_start'],\n",
       " [7.539, -1, 'P_lowering_stop'],\n",
       " [7.539, -1, 'P_swallow_stop'],\n",
       " [7.74, -1, 's_swallow_stop'],\n",
       " [8.5357, -1, 'stop'],\n",
       " [10.53, -1, 's_swallow_start'],\n",
       " [11.0007, -1, 'Schlucken normal'],\n",
       " [11.8, -1, 's_swallow_stop'],\n",
       " [15.45, -1, 's_swallow_start'],\n",
       " [15.463, -1, 'P_elevation_start'],\n",
       " [15.463, -1, 'P_swallow_start'],\n",
       " [16.079, -1, 'P_elevation_stop'],\n",
       " [16.079, -1, 'P_lowering_start'],\n",
       " [16.719, -1, 'P_lowering_stop'],\n",
       " [16.719, -1, 'P_swallow_stop'],\n",
       " [16.73, -1, 's_swallow_stop'],\n",
       " [18.3997, -1, 'stop'],\n",
       " [19.502, -1, 'C_category2_stop'],\n",
       " [20.3732, -1, 'Schlucken hoch'],\n",
       " [23.76, -1, 's_swallow_start'],\n",
       " [24.77, -1, 's_swallow_stop'],\n",
       " [26.7485, -1, 'stop'],\n",
       " [28.8607, -1, 'Schlucken hoch'],\n",
       " [30.98, -1, 's_swallow_start'],\n",
       " [32.03, -1, 's_swallow_stop'],\n",
       " [33.0822, -1, 'stop'],\n",
       " [34.8947, -1, 'Schlucken tief'],\n",
       " [37.36, -1, 's_swallow_start'],\n",
       " [39.07, -1, 's_swallow_stop'],\n",
       " [40.2047, -1, 'stop'],\n",
       " [41.9152, -1, 'Schlucken tief'],\n",
       " [43.81, -1, 's_swallow_start'],\n",
       " [45.39, -1, 's_swallow_stop'],\n",
       " [45.999, -1, 'stop'],\n",
       " [48.576, -1, 'Schlucken Knie re'],\n",
       " [54.44, -1, 's_swallow_start'],\n",
       " [56.2337, -1, 'stop'],\n",
       " [56.5, -1, 's_swallow_stop'],\n",
       " [58.7792, -1, 'Schlucken Knie li'],\n",
       " [61.07, -1, 's_swallow_start'],\n",
       " [62.71, -1, 's_swallow_stop'],\n",
       " [64.0495, -1, 'stop'],\n",
       " [67.543, -1, 'Mendelson'],\n",
       " [68.52, -1, 's_swallow_start'],\n",
       " [69.7, -1, 's_swallow_stop'],\n",
       " [79.005, -1, 'stop'],\n",
       " [81.05, -1, 'Mendelson'],\n",
       " [83.653, -1, 'P_swallow_start'],\n",
       " [83.66, -1, 's_swallow_start'],\n",
       " [85.24, -1, 's_swallow_stop'],\n",
       " [85.317, -1, 'P_swallow_stop'],\n",
       " [86.7565, -1, 'stop'],\n",
       " [92.9237, -1, 'Sprechen'],\n",
       " [97.8187, -1, 'stop'],\n",
       " [100.56, -1, 'Zunge'],\n",
       " [106.7885, -1, 'stop'],\n",
       " [108.7557, -1, 'Z..hne'],\n",
       " [109.63, -1, 's_swallow_start'],\n",
       " [112.18, -1, 's_swallow_stop'],\n",
       " [114.7772, -1, 'stop'],\n",
       " [118.2972, -1, 'Blick auf Knie re'],\n",
       " [123.7447, -1, 'stop'],\n",
       " [125.433, -1, 'Blick auf Knie li'],\n",
       " [128.539, -1, 'stop'],\n",
       " [134.1335, -1, 'Kopf rechts'],\n",
       " [139.4545, -1, 'stop'],\n",
       " [141.8857, -1, 'Kopf links'],\n",
       " [145.6482, -1, 'stop'],\n",
       " [148.05, -1, 'Kopf sch..tteln'],\n",
       " [152.1315, -1, 'stop'],\n",
       " [154.623, -1, 'Kopf heben'],\n",
       " [156.447, -1, 'P_movement_start'],\n",
       " [158.004, -1, 'P_movement_stop'],\n",
       " [159.4517, -1, 'stop'],\n",
       " [161.4805, -1, 'Kopf senken'],\n",
       " [162.616, -1, 'P_movement_start'],\n",
       " [163.881, -1, 'P_movement_stop'],\n",
       " [165.8442, -1, 'stop'],\n",
       " [169.2082, -1, 'Kopfnicken'],\n",
       " [172.2632, -1, 'stop'],\n",
       " [175.0072, -1, 'Luft'],\n",
       " [180.2162, -1, 'stop']]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_file['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_time(sampling_frequency, signal_array):\n",
    "        # Calculate the time array based on the length of the signal array and the sampling frequency\n",
    "        total_samples = len(signal_array)\n",
    "        time_array = np.arange(total_samples) / sampling_frequency\n",
    "        \n",
    "        return time_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess necessity of this function given that the general_df function should be enough\n",
    "def create_swallows_df(file, fileList=False):\n",
    "    swallow = iter(filter(lambda x : re.match(\"s_\", x[-1]), file[\"header\"][\"annotations\"]))\n",
    "\n",
    "    rows = {\"set\": [], \"filepath\": [], \"category\": [], \"sample_name\": [], \"start_time\": [], \"stop_time\": []}\n",
    "\n",
    "    for ann in swallow:\n",
    "        start_time, _, desc = ann\n",
    "        stop_time, _, _ = next(swallow)\n",
    "        \n",
    "        if not fileList:\n",
    "            rows[\"set\"].append(1)\n",
    "            rows[\"filepath\"].append(Path(file[\"filepath\"]).name)\n",
    "            rows[\"category\"].append(None)\n",
    "            rows[\"sample_name\"].append(desc)\n",
    "            rows[\"start_time\"].append(start_time)\n",
    "            rows[\"stop_time\"].append(stop_time)\n",
    "        else:\n",
    "            pass\n",
    "            # Implement file list input if necessary\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    \n",
    "    df['duration'] = df[\"stop_time\"] - df[\"start_time\"]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_general_df(file, fileList=False):\n",
    "    def find_first_element(list_data, condition):\n",
    "        for element in list_data:\n",
    "            if condition(element):\n",
    "                return element\n",
    "        return None\n",
    "    \n",
    "    def crop_signals_array(start_time, stop_time, file):\n",
    "        cropped_signals = []\n",
    "        for channel, signal in enumerate(file[\"signals\"]):\n",
    "            sr = file['signal_headers'][channel]['sample_rate']\n",
    "            start_idx = round(start_time * sr)\n",
    "            stop_idx = round(stop_time * sr) + 1\n",
    "            time_array = compute_time(sr, signal)\n",
    "            cropped_signals.append((time_array[start_idx: stop_idx], np.array(signal[start_idx: stop_idx])))\n",
    "        return list(zip(file['signal_headers'], np.array(cropped_signals)))\n",
    "\n",
    "    general = list(filter(lambda x : re.match(\"[pcts]_\", x[-1]), file[\"header\"][\"annotations\"]))\n",
    "\n",
    "    rows = {\"set\": [], \"subject\": [], \"category\": [], \"sample_name\": [],\n",
    "            \"start_time\": [], \"stop_time\": [],\n",
    "             \"header\": [], \"data_label\": [], \"time\": [], \"signal\": []}\n",
    "\n",
    "    for i, row in enumerate(general):\n",
    "        time, _, desc = row\n",
    "        s = desc.split(\"_\")\n",
    "        \n",
    "        if s[0] == \"c\":\n",
    "            if s[-1] == \"start\":\n",
    "                _, cat, _ = s\n",
    "            else:\n",
    "                cat = '-'\n",
    "            \n",
    "        else:\n",
    "            m, sample, event = s\n",
    "            if event == \"start\":\n",
    "                start_time = time\n",
    "                stop_time, _, _ = find_first_element(general[i:], lambda x: x[-1] == f\"{m}_{sample}_stop\")\n",
    "                if not fileList:\n",
    "                    signals = crop_signals_array(start_time, stop_time, file)\n",
    "                    for h, sigs in signals:\n",
    "                        rows[\"set\"].append(1)\n",
    "                        rows[\"subject\"].append(Path(file[\"filepath\"]).stem)\n",
    "                        rows[\"category\"].append(cat)\n",
    "                        rows[\"sample_name\"].append(s[1])\n",
    "                        rows[\"start_time\"].append(start_time)\n",
    "                        rows[\"stop_time\"].append(stop_time)\n",
    "                        rows[\"header\"].append(h)\n",
    "                        rows[\"data_label\"].append(h['label'])\n",
    "                        rows[\"time\"].append(sigs[0])\n",
    "                        rows[\"signal\"].append(sigs[1])\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    \n",
    "    df = df.explode(['time', 'signal']).reset_index(drop=True)\n",
    "    \n",
    "    df[\"id\"] = (df[\"subject\"] + df[\"category\"] + df[\"sample_name\"]).astype(\"category\")\n",
    "    df[\"data_label\"] = df[\"data_label\"].astype(\"category\")\n",
    "    \n",
    "    df[\"time\"] = df[\"time\"].astype(float)\n",
    "    df[\"signal\"] = df[\"signal\"].astype(float)\n",
    "    \n",
    "    cat_columns = df.select_dtypes(['category']).columns\n",
    "\n",
    "    df[cat_columns] = df[cat_columns].apply(lambda x: x.cat.codes)\n",
    "    \n",
    "    # df['duration'] = df[\"stop_time\"] - df[\"start_time\"]\n",
    "     \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = files[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annotations_validation import check_T_annotations, check_C_annotations\n",
    "\n",
    "def check_annotations(file: dict) -> bool:\n",
    "    match_pattern = r\"[cst]_\\w+_(start|stop)\"\n",
    "    annotations = file[\"header\"][\"annotations\"]\n",
    "    \n",
    "    if any(map(lambda x : not re.match(match_pattern, x[-1]), annotations)):\n",
    "        pattern_mismatches = [i for i, val in enumerate(map(lambda x : re.match(match_pattern, x[-1]), annotations)) if val is None]\n",
    "        print(f\"There are {len(pattern_mismatches)} annotations out of the pattern.\")\n",
    "        #for idx in pattern_mismatches:\n",
    "        #    print(idx, file[\"header\"][\"annotations\"][idx])\n",
    "    \n",
    "    if not annotations:\n",
    "        print(\"There are no annotations in the file.\")\n",
    "        return False\n",
    "    \n",
    "    elif check_C_annotations(list(filter(lambda x : x[-1].startswith(\"c_\"), annotations))):\n",
    "        if check_T_annotations(list(filter(lambda x : re.match(r\"[pts]_\", x[-1]), annotations))):\n",
    "            return True\n",
    "        return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'technician': 'Schultheiss',\n",
       " 'recording_additional': 'Bewegung, Ref.',\n",
       " 'patientname': 'Holger Nahrstaedt',\n",
       " 'patient_additional': 'gesund',\n",
       " 'patientcode': '1',\n",
       " 'equipment': 'Device-Nr.: 0',\n",
       " 'admincode': '',\n",
       " 'gender': 'Male',\n",
       " 'startdate': datetime.datetime(2010, 7, 20, 14, 45, 47),\n",
       " 'birthdate': '15 jun 1980',\n",
       " 'Duration': 182,\n",
       " 'SignalHeaders': [{'label': 'EMG 1',\n",
       "   'dimension': 'mV',\n",
       "   'sample_rate': 4000.0,\n",
       "   'sample_frequency': 4000.0,\n",
       "   'physical_max': 185.0,\n",
       "   'physical_min': -185.0,\n",
       "   'digital_max': 8388607,\n",
       "   'digital_min': -8388608,\n",
       "   'prefilter': '',\n",
       "   'transducer': 'transkutan'},\n",
       "  {'label': 'EMG 3',\n",
       "   'dimension': 'mV',\n",
       "   'sample_rate': 4000.0,\n",
       "   'sample_frequency': 4000.0,\n",
       "   'physical_max': 185.0,\n",
       "   'physical_min': -185.0,\n",
       "   'digital_max': 8388607,\n",
       "   'digital_min': -8388608,\n",
       "   'prefilter': '',\n",
       "   'transducer': 'transkutan'},\n",
       "  {'label': 'BI 1',\n",
       "   'dimension': 'Ohm',\n",
       "   'sample_rate': 4000.0,\n",
       "   'sample_frequency': 4000.0,\n",
       "   'physical_max': 24.81092,\n",
       "   'physical_min': -5.92731,\n",
       "   'digital_max': 8388607,\n",
       "   'digital_min': -8388608,\n",
       "   'prefilter': 'CS1 50kHz, 137uA, BI1 1: t(S1) gain 20x',\n",
       "   'transducer': 'transkutan'},\n",
       "  {'label': 'BI 2',\n",
       "   'dimension': 'Ohm',\n",
       "   'sample_rate': 4000.0,\n",
       "   'sample_frequency': 4000.0,\n",
       "   'physical_max': 144.799,\n",
       "   'physical_min': -7.23991,\n",
       "   'digital_max': 8388607,\n",
       "   'digital_min': -8388608,\n",
       "   'prefilter': 'CS2 100kHz, 113uA, BI2  gain 15x',\n",
       "   'transducer': 'transkutan'},\n",
       "  {'label': 'sync',\n",
       "   'dimension': 'no',\n",
       "   'sample_rate': 4000.0,\n",
       "   'sample_frequency': 4000.0,\n",
       "   'physical_max': 1.0,\n",
       "   'physical_min': 0.0,\n",
       "   'digital_max': 8388607,\n",
       "   'digital_min': -8388608,\n",
       "   'prefilter': '',\n",
       "   'transducer': ''}],\n",
       " 'channels': ['EMG 1', 'EMG 3', 'BI 1', 'BI 2', 'sync'],\n",
       " 'annotations': [[2.8425, -1, 'Schlucken normal'],\n",
       "  [5.925, -1, 'C_category2_start'],\n",
       "  [6.64, -1, 's_swallow_start'],\n",
       "  [6.687, -1, 'P_elevation_start'],\n",
       "  [6.687, -1, 'P_swallow_start'],\n",
       "  [7.304, -1, 'P_elevation_stop'],\n",
       "  [7.304, -1, 'P_lowering_start'],\n",
       "  [7.539, -1, 'P_lowering_stop'],\n",
       "  [7.539, -1, 'P_swallow_stop'],\n",
       "  [7.74, -1, 's_swallow_stop'],\n",
       "  [8.5357, -1, 'stop'],\n",
       "  [10.53, -1, 's_swallow_start'],\n",
       "  [11.0007, -1, 'Schlucken normal'],\n",
       "  [11.8, -1, 's_swallow_stop'],\n",
       "  [15.45, -1, 's_swallow_start'],\n",
       "  [15.463, -1, 'P_elevation_start'],\n",
       "  [15.463, -1, 'P_swallow_start'],\n",
       "  [16.079, -1, 'P_elevation_stop'],\n",
       "  [16.079, -1, 'P_lowering_start'],\n",
       "  [16.719, -1, 'P_lowering_stop'],\n",
       "  [16.719, -1, 'P_swallow_stop'],\n",
       "  [16.73, -1, 's_swallow_stop'],\n",
       "  [18.3997, -1, 'stop'],\n",
       "  [19.502, -1, 'C_category2_stop'],\n",
       "  [20.3732, -1, 'Schlucken hoch'],\n",
       "  [23.76, -1, 's_swallow_start'],\n",
       "  [24.77, -1, 's_swallow_stop'],\n",
       "  [26.7485, -1, 'stop'],\n",
       "  [28.8607, -1, 'Schlucken hoch'],\n",
       "  [30.98, -1, 's_swallow_start'],\n",
       "  [32.03, -1, 's_swallow_stop'],\n",
       "  [33.0822, -1, 'stop'],\n",
       "  [34.8947, -1, 'Schlucken tief'],\n",
       "  [37.36, -1, 's_swallow_start'],\n",
       "  [39.07, -1, 's_swallow_stop'],\n",
       "  [40.2047, -1, 'stop'],\n",
       "  [41.9152, -1, 'Schlucken tief'],\n",
       "  [43.81, -1, 's_swallow_start'],\n",
       "  [45.39, -1, 's_swallow_stop'],\n",
       "  [45.999, -1, 'stop'],\n",
       "  [48.576, -1, 'Schlucken Knie re'],\n",
       "  [54.44, -1, 's_swallow_start'],\n",
       "  [56.2337, -1, 'stop'],\n",
       "  [56.5, -1, 's_swallow_stop'],\n",
       "  [58.7792, -1, 'Schlucken Knie li'],\n",
       "  [61.07, -1, 's_swallow_start'],\n",
       "  [62.71, -1, 's_swallow_stop'],\n",
       "  [64.0495, -1, 'stop'],\n",
       "  [67.543, -1, 'Mendelson'],\n",
       "  [68.52, -1, 's_swallow_start'],\n",
       "  [69.7, -1, 's_swallow_stop'],\n",
       "  [79.005, -1, 'stop'],\n",
       "  [81.05, -1, 'Mendelson'],\n",
       "  [83.653, -1, 'P_swallow_start'],\n",
       "  [83.66, -1, 's_swallow_start'],\n",
       "  [85.24, -1, 's_swallow_stop'],\n",
       "  [85.317, -1, 'P_swallow_stop'],\n",
       "  [86.7565, -1, 'stop'],\n",
       "  [92.9237, -1, 'Sprechen'],\n",
       "  [97.8187, -1, 'stop'],\n",
       "  [100.56, -1, 'Zunge'],\n",
       "  [106.7885, -1, 'stop'],\n",
       "  [108.7557, -1, 'Z..hne'],\n",
       "  [109.63, -1, 's_swallow_start'],\n",
       "  [112.18, -1, 's_swallow_stop'],\n",
       "  [114.7772, -1, 'stop'],\n",
       "  [118.2972, -1, 'Blick auf Knie re'],\n",
       "  [123.7447, -1, 'stop'],\n",
       "  [125.433, -1, 'Blick auf Knie li'],\n",
       "  [128.539, -1, 'stop'],\n",
       "  [134.1335, -1, 'Kopf rechts'],\n",
       "  [139.4545, -1, 'stop'],\n",
       "  [141.8857, -1, 'Kopf links'],\n",
       "  [145.6482, -1, 'stop'],\n",
       "  [148.05, -1, 'Kopf sch..tteln'],\n",
       "  [152.1315, -1, 'stop'],\n",
       "  [154.623, -1, 'Kopf heben'],\n",
       "  [156.447, -1, 'P_movement_start'],\n",
       "  [158.004, -1, 'P_movement_stop'],\n",
       "  [159.4517, -1, 'stop'],\n",
       "  [161.4805, -1, 'Kopf senken'],\n",
       "  [162.616, -1, 'P_movement_start'],\n",
       "  [163.881, -1, 'P_movement_stop'],\n",
       "  [165.8442, -1, 'stop'],\n",
       "  [169.2082, -1, 'Kopfnicken'],\n",
       "  [172.2632, -1, 'stop'],\n",
       "  [175.0072, -1, 'Luft'],\n",
       "  [180.2162, -1, 'stop']]}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "file[\"header\"][\"annotations\"] = list(map(lambda x: [x[0], x[1], x[2].lower()], file[\"header\"][\"annotations\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2.8425, -1.0, 'schlucken normal'],\n",
       " [5.925, -1.0, 'c_category2_start'],\n",
       " [6.687, -1.0, 'p_elevation_start'],\n",
       " [6.687, -1.0, 'p_swallow_start'],\n",
       " [7.304, -1.0, 'p_elevation_stop'],\n",
       " [7.304, -1.0, 'p_lowering_start'],\n",
       " [7.539, -1.0, 'p_lowering_stop'],\n",
       " [7.539, -1.0, 'p_swallow_stop'],\n",
       " [8.5357, -1.0, 'stop'],\n",
       " [11.0007, -1.0, 'schlucken normal'],\n",
       " [15.463, -1.0, 'p_elevation_start'],\n",
       " [15.463, -1.0, 'p_swallow_start'],\n",
       " [16.079, -1.0, 'p_elevation_stop'],\n",
       " [16.079, -1.0, 'p_lowering_start'],\n",
       " [16.719, -1.0, 'p_lowering_stop'],\n",
       " [16.719, -1.0, 'p_swallow_stop'],\n",
       " [18.3997, -1.0, 'stop'],\n",
       " [19.502, -1.0, 'c_category2_stop'],\n",
       " [20.3732, -1.0, 'schlucken hoch'],\n",
       " [26.7485, -1.0, 'stop'],\n",
       " [28.8607, -1.0, 'schlucken hoch'],\n",
       " [33.0822, -1.0, 'stop'],\n",
       " [34.8947, -1.0, 'schlucken tief'],\n",
       " [40.2047, -1.0, 'stop'],\n",
       " [41.9152, -1.0, 'schlucken tief'],\n",
       " [45.999, -1.0, 'stop'],\n",
       " [48.576, -1.0, 'schlucken knie re'],\n",
       " [56.2337, -1.0, 'stop'],\n",
       " [58.7792, -1.0, 'schlucken knie li'],\n",
       " [64.0495, -1.0, 'stop'],\n",
       " [67.543, -1.0, 'mendelson'],\n",
       " [79.005, -1.0, 'stop'],\n",
       " [81.05, -1.0, 'mendelson'],\n",
       " [83.653, -1.0, 'p_swallow_start'],\n",
       " [85.317, -1.0, 'p_swallow_stop'],\n",
       " [86.7565, -1.0, 'stop'],\n",
       " [92.9237, -1.0, 'sprechen'],\n",
       " [97.8187, -1.0, 'stop'],\n",
       " [100.56, -1.0, 'zunge'],\n",
       " [106.7885, -1.0, 'stop'],\n",
       " [108.7557, -1.0, 'z..hne'],\n",
       " [114.7772, -1.0, 'stop'],\n",
       " [118.2972, -1.0, 'blick auf knie re'],\n",
       " [123.7447, -1.0, 'stop'],\n",
       " [125.433, -1.0, 'blick auf knie li'],\n",
       " [128.539, -1.0, 'stop'],\n",
       " [134.1335, -1.0, 'kopf rechts'],\n",
       " [139.4545, -1.0, 'stop'],\n",
       " [141.8857, -1.0, 'kopf links'],\n",
       " [145.6482, -1.0, 'stop'],\n",
       " [148.05, -1.0, 'kopf sch..tteln'],\n",
       " [152.1315, -1.0, 'stop'],\n",
       " [154.623, -1.0, 'kopf heben'],\n",
       " [156.447, -1.0, 'p_movement_start'],\n",
       " [158.004, -1.0, 'p_movement_stop'],\n",
       " [159.4517, -1.0, 'stop'],\n",
       " [161.4805, -1.0, 'kopf senken'],\n",
       " [162.616, -1.0, 'p_movement_start'],\n",
       " [163.881, -1.0, 'p_movement_stop'],\n",
       " [165.8442, -1.0, 'stop'],\n",
       " [169.2082, -1.0, 'kopfnicken'],\n",
       " [172.2632, -1.0, 'stop'],\n",
       " [175.0072, -1.0, 'luft'],\n",
       " [180.2162, -1.0, 'stop']]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file[\"header\"][\"annotations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file[\"header\"][\"annotations\"].append([15.20, -1, 't_swall_start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file[\"header\"][\"annotations\"].pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 62 annotations out of the pattern.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_annotations(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>set</th>\n",
       "      <th>filepath</th>\n",
       "      <th>category</th>\n",
       "      <th>sample_name</th>\n",
       "      <th>start_time</th>\n",
       "      <th>stop_time</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [set, filepath, category, sample_name, start_time, stop_time, duration]\n",
       "Index: []"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swallows_df = create_swallows_df(file)\n",
    "swallows_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>6.68700</td>\n",
       "      <td>-10.326908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6.68725</td>\n",
       "      <td>-10.325298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6.68750</td>\n",
       "      <td>-10.335906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>6.68775</td>\n",
       "      <td>-10.338045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>6.68800</td>\n",
       "      <td>-10.349182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153836</th>\n",
       "      <td>0</td>\n",
       "      <td>163.88000</td>\n",
       "      <td>-9.764163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153837</th>\n",
       "      <td>0</td>\n",
       "      <td>163.88025</td>\n",
       "      <td>-9.761517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153838</th>\n",
       "      <td>0</td>\n",
       "      <td>163.88050</td>\n",
       "      <td>-9.768949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153839</th>\n",
       "      <td>0</td>\n",
       "      <td>163.88075</td>\n",
       "      <td>-9.768949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153840</th>\n",
       "      <td>0</td>\n",
       "      <td>163.88100</td>\n",
       "      <td>-9.765751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34817 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       time     signal\n",
       "0        2    6.68700 -10.326908\n",
       "1        2    6.68725 -10.325298\n",
       "2        2    6.68750 -10.335906\n",
       "3        2    6.68775 -10.338045\n",
       "4        2    6.68800 -10.349182\n",
       "...     ..        ...        ...\n",
       "153836   0  163.88000  -9.764163\n",
       "153837   0  163.88025  -9.761517\n",
       "153838   0  163.88050  -9.768949\n",
       "153839   0  163.88075  -9.768949\n",
       "153840   0  163.88100  -9.765751\n",
       "\n",
       "[34817 rows x 3 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general_df = create_general_df(file)\n",
    "final = general_df.loc[general_df['data_label'] == 2, ['id', 'time', 'signal']]\n",
    "final"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSFresh tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh import extract_features, extract_relevant_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters, MinimalFCParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your extraction settings (optional)\n",
    "extraction_settings = MinimalFCParameters()\n",
    "\n",
    "# # Remove the 'sample_entropy' calculation from the extraction settings\n",
    "# extraction_settings.pop('sample_entropy', None)\n",
    "\n",
    "# Perform feature extraction without the 'sample_entropy' calculation\n",
    "X = extract_features(final.head(15000), column_id='id', column_sort='time',\n",
    "                     #column_kind='data_label', column_value='signal',\n",
    "                     default_fc_parameters=extraction_settings,\n",
    "                     impute_function=impute\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_excel('data/xlsx/bewegungs_edited-data-label-2_minimal.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
